{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f961e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e33aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca1c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(letter):\n",
    "    # Creating driver for each letter instance and using template url\n",
    "    service = Service(executable_path=\"/usr/local/bin\")\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(\"--disable-javascript\")\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    template_url = 'https://www.basketball-reference.com{}'\n",
    "    letter_url = 'https://www.basketball-reference.com/players/{}/'.format(letter)\n",
    "    \n",
    "    # Scanning entire page to get list of players\n",
    "    driver.get(letter_url)\n",
    "    html_main = driver.page_source\n",
    "    soup = BeautifulSoup(html_main, \"lxml\")\n",
    "    \n",
    "    # Create array of all players without header rows\n",
    "    all_players = soup.find(id=\"players\")\n",
    "    all_player_rows = all_players.find_all(\"tr\", class_=lambda x: x is None or 'thead' not in x.split())\n",
    "    \n",
    "    \n",
    "    folder = \"threadedPlayers/{}\".format(letter)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # writing code to store all \"Letter\" players in a folder to look at later\n",
    "    for i in range(len(all_player_rows) - 1):\n",
    "        player_link = [a['href'] for a in all_player_rows[i+1].find_all('a', href=True)][0]\n",
    "        player_name = all_player_rows[i+1].find('a').text\n",
    "        full_url = template_url.format(player_link)\n",
    "        print(f\"Scraping for '{player_name}'\")\n",
    "        \n",
    "        if os.path.exists(folder + \"/{}.html\".format(player_name)):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            driver.get(full_url)\n",
    "            driver.execute_script(\"window.scrollTo(1, 100000)\")\n",
    "            time.sleep(2)\n",
    "            full_html = driver.page_source\n",
    "    \n",
    "            # Writing results to folder\n",
    "            with open(folder + \"/{}.html\".format(player_name), \"w+\") as f:\n",
    "                f.write(full_html)\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout occurred for '{player_name}'. Skipping to the next player.\")\n",
    "            continue\n",
    "    \n",
    "    driver.close()\n",
    "    print(f\"Scraping for letter '{letter}' completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea444049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for letter 'b' started...\n",
      "Scraping for letter 'c' started...\n",
      "Scraping for letter 'd' started...\n",
      "Scraping for letter 'e' started...\n",
      "Scraping for 'Mike D'Antoni'\n",
      "Scraping for 'Mike Dabich'\n",
      "Scraping for 'Ed Dahler'\n",
      "Scraping for 'Quintin Dailey'\n",
      "Scraping for 'Samuel Dalembert'\n",
      "Scraping for 'Howie Dallmar'\n",
      "Scraping for 'Erick Dampier'\n",
      "Scraping for 'Louie Dampier'\n",
      "Scraping for 'Bob Dandridge'\n",
      "Scraping for 'Antonio Daniels'\n",
      "Scraping for 'Dyson Daniels'\n",
      "Scraping for 'Erik Daniels'\n",
      "Scraping for 'Chris Babb'\n",
      "Scraping for 'Luke Babbitt'\n",
      "Scraping for 'Miloš Babić'\n",
      "Scraping for 'Johnny Bach'\n",
      "Scraping for 'Dwayne Bacon'\n",
      "Scraping for 'Henry Bacon'\n",
      "Scraping for 'Jim Baechtold'\n",
      "Scraping for 'Dalibor Bagarić'\n",
      "Scraping for 'John Bagley'\n",
      "Scraping for 'Marvin Bagley III'\n",
      "Scraping for 'Carl Bailey'\n",
      "Scraping for 'Gus Bailey'\n",
      "Scraping for 'James Bailey'\n",
      "Scraping for 'Thurl Bailey'\n",
      "Scraping for 'Toby Bailey'\n",
      "Scraping for 'Cameron Bairstow'\n",
      "Scraping for 'Jimmie Baker'\n",
      "Scraping for 'Mark Baker'\n",
      "Scraping for 'Maurice Baker'\n",
      "Scraping for 'Norm Baker'\n",
      "Scraping for 'Ron Baker'\n",
      "Scraping for 'Vin Baker'\n",
      "Scraping for 'Patrick Baldwin Jr.'\n",
      "Scraping for 'Wade Baldwin'\n",
      "Scraping for 'Renaldo Balkman'\n",
      "Scraping for 'Žarko Čabarkapa'\n",
      "Scraping for 'Barney Cable'\n",
      "Scraping for 'Bruno Caboclo'\n",
      "Scraping for 'Devontae Cacok'\n",
      "Scraping for 'Jason Caffey'\n",
      "Scraping for 'Michael Cage'\n",
      "Scraping for 'Ledell Eackles'\n",
      "Scraping for 'Jim Eakins'\n",
      "Scraping for 'Acie Earl'\n",
      "Scraping for 'Ed Earle'\n",
      "Scraping for 'Cleanthony Early'\n",
      "Scraping for 'Penny Early'\n",
      "Scraping for 'Tari Eason'\n",
      "Scraping for 'Mark Eaton'\n",
      "Scraping for 'Jerry Eaves'\n",
      "Scraping for 'Devin Ebanks'\n",
      "Scraping for 'Bill Ebben'\n",
      "Scraping for 'Al Eberhard'\n",
      "Scraping for 'Ndudi Ebi'\n",
      "Scraping for 'Roy Ebron'\n",
      "Scraping for 'Jaime Echenique'\n",
      "Scraping for 'Jarell Eddie'\n",
      "Scraping for 'Patrick Eddie'\n",
      "Scraping for 'Dike Eddleman'\n",
      "Scraping for 'Kenton Edelin'\n",
      "Scraping for 'Charles Edge'\n",
      "Scraping for 'Bobby Edmonds'\n",
      "Scraping for 'Keith Edmonson'\n",
      "Scraping for 'Tyus Edney'\n",
      "Scraping for 'Anthony Edwards'\n",
      "Scraping for 'Cedric Ball'\n",
      "Scraping for 'Lloyd Daniels'\n",
      "Scraping for 'Jamal Cain'\n",
      "Scraping for 'Bill Edwards'\n",
      "Scraping for 'LaMelo Ball'\n",
      "Scraping for 'Gerry Calabrese'\n",
      "Scraping for 'Marquis Daniels'\n",
      "Scraping for 'Lonzo Ball'\n",
      "Scraping for 'Blue Edwards'\n",
      "Scraping for 'Greg Ballard'\n",
      "Timeout occurred for 'Gerry Calabrese'. Skipping to the next player.\n",
      "Scraping for 'Nick Calathes'\n",
      "Scraping for 'Herschel Baltimore'\n",
      "Timeout occurred for 'Marquis Daniels'. Skipping to the next player.\n",
      "Scraping for 'Mel Daniels'\n",
      "Timeout occurred for 'Blue Edwards'. Skipping to the next player.\n",
      "Scraping for 'Carsen Edwards'\n",
      "Timeout occurred for 'Herschel Baltimore'. Skipping to the next player.\n",
      "Scraping for 'Mo Bamba'\n",
      "Scraping for 'José Calderón'\n",
      "Timeout occurred for 'Mel Daniels'. Skipping to the next player.\n",
      "Scraping for 'Troy Daniels'\n",
      "Timeout occurred for 'Carsen Edwards'. Skipping to the next player.\n",
      "Scraping for 'Corsley Edwards'\n",
      "Timeout occurred for 'Mo Bamba'. Skipping to the next player.\n",
      "Scraping for 'Paolo Banchero'\n",
      "Timeout occurred for 'José Calderón'. Skipping to the next player.\n",
      "Scraping for 'Adrian Caldwell'\n"
     ]
    }
   ],
   "source": [
    "# FOR LOOP TO RUN FOR ALL LETTERS\n",
    "\n",
    "# List of letters to process concurrently\n",
    "letters = ['b', 'c', 'd', 'e']\n",
    "\n",
    "\n",
    "# Create threads for each letter and start them\n",
    "threads = []\n",
    "for letter in letters:\n",
    "    thread = threading.Thread(target=main, args=(letter))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "    print(f\"Scraping for letter '{letter}' started...\")\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"Scraping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c1238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
