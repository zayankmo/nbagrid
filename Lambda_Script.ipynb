{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f961e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca1c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(letter):\n",
    "    # Creating driver for each letter instance and using template url\n",
    "    service = Service(executable_path=\"/usr/local/bin\")\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(\"--disable-javascript\")\n",
    "    #options.set_page_load_timeout(600) # NEW, double the default time\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    template_url = 'https://www.basketball-reference.com{}'\n",
    "    letter_url = 'https://www.basketball-reference.com/players/{}/'.format(letter)\n",
    "    \n",
    "    # Scanning entire page to get list of players\n",
    "    driver.get(letter_url)\n",
    "    html_main = driver.page_source\n",
    "    soup = BeautifulSoup(html_main, \"lxml\")\n",
    "    \n",
    "    # Create array of all players without header rows\n",
    "    all_players = soup.find(id=\"players\")\n",
    "    all_player_rows = all_players.find_all(\"tr\", class_=lambda x: x is None or 'thead' not in x.split())\n",
    "    \n",
    "    \n",
    "    folder = \"threadedPlayers/{}\".format(letter)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # writing code to store all \"Letter\" players in a folder to look at later\n",
    "    for i in range(len(all_player_rows) - 1):\n",
    "        start_time = time.process_time()\n",
    "        player_link = [a['href'] for a in all_player_rows[i+1].find_all('a', href=True)][0]\n",
    "        player_name = all_player_rows[i+1].find('a').text\n",
    "        full_url = template_url.format(player_link)\n",
    "        \n",
    "        if os.path.exists(folder + \"/{}.html\".format(player_name)):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(f\"Scraping for '{player_name}'\")\n",
    "            driver.get(full_url)\n",
    "            driver.execute_script(\"window.scrollTo(1, 100000)\")\n",
    "            time.sleep(5) # NEW, before it was set to 2\n",
    "            full_html = driver.page_source\n",
    "    \n",
    "            # Writing results to folder\n",
    "            with open(folder + \"/{}.html\".format(player_name), \"w+\") as f:\n",
    "                f.write(full_html)\n",
    "            finish_time = (time.process_time() - start_time)\n",
    "            print(f\"Duration: for '{player_name}' is {finish_time}\")\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout occurred for '{player_name}'. Skipping to the next player.\")\n",
    "            time.sleep(30) # NEW, before it was 5\n",
    "            continue\n",
    "    \n",
    "    driver.quit()\n",
    "    print(f\"Scraping for letter '{letter}' completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea444049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for letter 'b' started...\n",
      "Scraping for letter 'c' started...\n",
      "Scraping for 'Tyler Cook'\n",
      "Scraping for 'Lionel Billingy'\n",
      "Duration: for 'Lionel Billingy' is 0.009977000000000125\n",
      "Scraping for 'Bismack Biyombo'\n",
      "Duration: for 'Bismack Biyombo' is 0.015451000000000104\n",
      "Scraping for 'Nemanja Bjelica'\n",
      "Duration: for 'Tyler Cook' is 0.11741099999999971\n",
      "Scraping for 'Lanard Copeland'\n",
      "Duration: for 'Nemanja Bjelica' is 0.026621000000000006\n",
      "Scraping for 'Rolando Blackman'\n",
      "Duration: for 'Lanard Copeland' is 0.021675999999999807\n",
      "Scraping for 'Tyrone Corbin'\n",
      "Duration: for 'Rolando Blackman' is 0.023149000000000086\n",
      "Scraping for 'Antonio Blakeney'\n",
      "Duration: for 'Tyrone Corbin' is 0.02984700000000018\n",
      "Scraping for 'Allen Crabbe'\n",
      "Duration: for 'Allen Crabbe' is 0.013257000000000296\n",
      "Scraping for 'Corey Crowder'\n",
      "Duration: for 'Antonio Blakeney' is 0.03990500000000008\n",
      "Scraping for 'Lance Blanks'\n",
      "Duration: for 'Corey Crowder' is 0.029654999999999987\n",
      "Scraping for 'Jae Crowder'\n",
      "Duration: for 'Lance Blanks' is 0.03766500000000006\n",
      "Scraping for 'Ricky Blanton'\n",
      "Timeout occurred for 'Jae Crowder'. Skipping to the next player.\n",
      "Scraping for 'Al Cueto'\n",
      "Timeout occurred for 'Ricky Blanton'. Skipping to the next player.\n",
      "Scraping for 'Corie Blount'\n",
      "Duration: for 'Al Cueto' is 0.03865099999999977\n",
      "Scraping for 'Jarrett Culver'\n",
      "Duration: for 'Corie Blount' is 0.03643699999999983\n",
      "Scraping for 'Nelson Bobb'\n",
      "Duration: for 'Jarrett Culver' is 0.02613500000000002\n",
      "Scraping for 'Jarron Cumberland'\n",
      "Duration: for 'Nelson Bobb' is 0.02460299999999993\n",
      "Scraping for 'Bucky Bockhorn'\n",
      "Duration: for 'Bucky Bockhorn' is 0.019731000000000165\n",
      "Scraping for 'Bojan Bogdanović'\n",
      "Duration: for 'Jarron Cumberland' is 0.03922099999999995\n",
      "Scraping for 'Pat Cummings'\n",
      "Duration: for 'Bojan Bogdanović' is 0.02911700000000028\n",
      "Scraping for 'Andrew Bogut'\n",
      "Duration: for 'Pat Cummings' is 0.03185400000000005\n",
      "Scraping for 'Terry Cummings'\n",
      "Duration: for 'Andrew Bogut' is 0.029950999999999617\n",
      "Scraping for 'Etdrick Bohannon'\n",
      "Duration: for 'Terry Cummings' is 0.03423500000000024\n",
      "Scraping for 'Vonteego Cummings'\n",
      "Duration: for 'Vonteego Cummings' is 0.014271000000000367\n",
      "Scraping for 'Billy Cunningham'\n",
      "Duration: for 'Etdrick Bohannon' is 0.03671699999999989\n",
      "Scraping for 'Marques Bolden'\n",
      "Duration: for 'Marques Bolden' is 0.013488000000000167\n",
      "Scraping for 'Doug Bolstorff'\n",
      "Duration: for 'Billy Cunningham' is 0.03651900000000019\n",
      "Scraping for 'Cade Cunningham'\n",
      "Duration: for 'Doug Bolstorff' is 0.023922999999999917\n",
      "Scraping for 'Phil Bond'\n",
      "Duration: for 'Cade Cunningham' is 0.026572999999999958\n",
      "Scraping for 'Dante Cunningham'\n",
      "Duration: for 'Phil Bond' is 0.022437999999999736\n",
      "Scraping for 'Dexter Boney'\n",
      "Duration: for 'Dexter Boney' is 0.013732000000000077\n",
      "Scraping for 'Devin Booker'\n",
      "Duration: for 'Dante Cunningham' is 0.03701100000000013\n",
      "Scraping for 'Dick Cunningham'\n",
      "Duration: for 'Devin Booker' is 0.03735500000000025\n",
      "Scraping for 'Carlos Boozer'\n",
      "Duration: for 'Dick Cunningham' is 0.04109099999999977\n",
      "Scraping for 'Jared Cunningham'\n",
      "Duration: for 'Carlos Boozer' is 0.03241800000000028\n",
      "Scraping for 'Lazaro Borrell'\n",
      "Duration: for 'Jared Cunningham' is 0.03457999999999961\n",
      "Scraping for 'William Cunningham'\n",
      "Duration: for 'Lazaro Borrell' is 0.025617\n",
      "Scraping for 'Vince Boryla'\n",
      "Duration: for 'Vince Boryla' is 0.016198999999999852\n",
      "Scraping for 'Brandon Boston Jr.'\n",
      "Duration: for 'William Cunningham' is 0.03563099999999997\n",
      "Scraping for 'Radisav Ćurčić'\n",
      "Duration: for 'Brandon Boston Jr.' is 0.017752999999999908\n",
      "Scraping for 'Lawrence Boston'\n",
      "Duration: for 'Radisav Ćurčić' is 0.021475000000000133\n",
      "Scraping for 'Armand Cure'\n"
     ]
    }
   ],
   "source": [
    "# FOR LOOP TO RUN FOR ALL LETTERS\n",
    "\n",
    "# List of letters to process concurrently\n",
    "letters = ['b', 'c']\n",
    "\n",
    "\n",
    "\"\"\"# Create threads for each letter and start them\n",
    "threads = []\n",
    "for letter in letters:\n",
    "    thread = threading.Thread(target=main, args=(letter, ))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "    print(f\"Scraping for letter '{letter}' started...\")\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"Scraping completed!\") \"\"\"\n",
    "\n",
    "\n",
    "# Using ThreadPoolExecutor to submit tasks for each letter\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Create a list of futures for the scraping tasks\n",
    "    futures = []\n",
    "\n",
    "    for letter in letters:\n",
    "        # Submit tasks for each letter to the executor\n",
    "        future = executor.submit(main, letter)\n",
    "        futures.append(future)\n",
    "\n",
    "        print(f\"Scraping for letter '{letter}' started...\")\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "    print(\"Scraping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c1238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
